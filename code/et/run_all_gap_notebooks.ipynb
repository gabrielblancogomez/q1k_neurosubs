{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gap Analysis Notebook\n",
    "\n",
    "This notebook orchestrates the execution of multiple Gap analysis notebooks using Papermill, allowing for automated parameter injection and HTML report generation.\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "The notebook executes the following analysis pipeline:\n",
    "\n",
    "1. **Gap ET Extraction** (`1_gap_et_extraction.ipynb`)\n",
    "   - Extracts eye-tracking data and demographics\n",
    "   - Parameters: `date`, `files_date`, `derivative`\n",
    "\n",
    "2. **Gap Data Preprocessing** (`2_gap_et_preprocessing.ipynb`) \n",
    "   - Comprehensive preprocessing and quality control\n",
    "   - Parameters: `date`, `files_date`, `derivative`, `outlier_rem`, `min_n_trials_per_condition`, `full_preprocessing`\n",
    "\n",
    "3. **Additional Analysis** (using preprocessing notebook with different parameters)\n",
    "   - Runs specific analysis configurations\n",
    "   - Allows for parameter variations and comparisons\n",
    "\n",
    "## üîß Key Features\n",
    "\n",
    "- **Flexible Parameter Handling**: Each notebook gets only the parameters it needs\n",
    "- **Error Handling**: Robust error reporting and continuation\n",
    "- **Output Management**: Organized HTML reports in separate directories\n",
    "- **Progress Tracking**: Clear status updates during execution\n",
    "\n",
    "## üìÅ Output Structure\n",
    "\n",
    "```\n",
    "papermill_outputs/\n",
    "‚îú‚îÄ‚îÄ gap_et_extraction/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ gap_et_extraction_papermill.html\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ gap_et_extraction_papermill_executed.ipynb\n",
    "‚îú‚îÄ‚îÄ gap_et_preprocessing/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ gap_et_preprocessing_papermill.html\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ gap_et_preprocessing_papermill_executed.ipynb\n",
    "‚îî‚îÄ‚îÄ gap_additional_analysis/\n",
    "    ‚îú‚îÄ‚îÄ gap_analysis_outliers_removed_[date].html\n",
    "    ‚îî‚îÄ‚îÄ gap_analysis_outliers_removed_[date]_executed.ipynb\n",
    "```\n",
    "\n",
    "## üöÄ Usage\n",
    "\n",
    "1. Update date parameters as needed\n",
    "2. Modify notebook-specific parameters in their respective sections\n",
    "3. Run all cells to execute the complete pipeline\n",
    "4. Check generated HTML reports for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "from nbclient import NotebookClient\n",
    "from pathlib import Path\n",
    "import papermill as pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_notebook_with_papermill(notebook_path, output_html, **parameters):\n",
    "    \"\"\"Execute a Jupyter notebook with specified parameters using Papermill.\n",
    "\n",
    "    Args:\n",
    "        notebook_path (str): Path to the notebook to execute.\n",
    "        output_html (str): Path to save the HTML output of the notebook.\n",
    "        **parameters: Keyword arguments to pass as parameters to the notebook.\n",
    "    \"\"\"\n",
    "    print(f\"Executing notebook: {Path(notebook_path).name}\")\n",
    "    print(f\"Parameters: {parameters}\")\n",
    "    \n",
    "    # Load the current notebook to get the kernel information\n",
    "    with open(notebook_path, \"r\") as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Extract the kernel name used in the current notebook\n",
    "    kernel_name = notebook.metadata.get('kernelspec', {}).get('name', 'python3')\n",
    "\n",
    "    # Execute the notebook with Papermill\n",
    "    executed_notebook_path = output_html.replace(\".html\", \"_executed.ipynb\")\n",
    "    \n",
    "    try:\n",
    "        # Execute with parameters - only pass non-None parameters\n",
    "        filtered_parameters = {k: v for k, v in parameters.items() if v is not None}\n",
    "        \n",
    "        pm.execute_notebook(\n",
    "            notebook_path,\n",
    "            executed_notebook_path,\n",
    "            parameters=filtered_parameters,\n",
    "            kernel_name=kernel_name        \n",
    "        )\n",
    "\n",
    "        # Convert the executed notebook to HTML\n",
    "        html_exporter = HTMLExporter()\n",
    "        html_exporter.exclude_input = True  # Exclude input cells for cleaner output\n",
    "        \n",
    "        with open(executed_notebook_path, \"r\") as f:\n",
    "            executed_notebook = nbformat.read(f, as_version=4)\n",
    "            html_content, _ = html_exporter.from_notebook_node(executed_notebook)\n",
    "        \n",
    "        # Save HTML output\n",
    "        with open(output_html, \"w\") as html_file:\n",
    "            html_file.write(html_content)\n",
    "\n",
    "        print(f\"‚úì Successfully executed and saved to: {output_html}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error executing notebook: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    return executed_notebook_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Notebook Execution Pipeline\n",
    "\n",
    "## 1. Gap ET Extraction and Demographics\n",
    "\n",
    "Extracts raw eye-tracking data and participant demographics from the Gap task files. This notebook handles the initial data extraction and basic quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run gap extraction notebook\n",
      "Executing notebook: 1_gap_et_extraction.ipynb\n",
      "Parameters: {'date': '2025_06_29'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36383d1df68d496c9814694ebf78958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/60 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Successfully executed and saved to: papermill_outputs\\gap_et_extraction\\gap_et_extraction_papermill.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'papermill_outputs\\\\gap_et_extraction\\\\gap_et_extraction_papermill_executed.ipynb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths\n",
    "notebook_to_run = \"C:/Users/gabot/OneDrive - McGill University/Desktop/github_repos/q1k_neurosubs/code/et/1_gap_et_extraction.ipynb\"\n",
    "out_dir = Path(\"papermill_outputs/gap_et_extraction\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Parameters specific to extraction notebook\n",
    "extraction_params = {\n",
    "    \"date\": \"2025_06_29\"}\n",
    "\n",
    "print(\"Run gap extraction notebook\")\n",
    "\n",
    "execute_notebook_with_papermill(\n",
    "        notebook_path=notebook_to_run,\n",
    "                output_html=str(out_dir / \"gap_et_extraction_papermill.html\"),\n",
    "    **extraction_params\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gap Data Preprocessing\n",
    "\n",
    "Performs comprehensive preprocessing of the extracted Gap task data, including:\n",
    "- Trial validity assessment and exclusion criteria\n",
    "- Participant-level quality control\n",
    "- Eye-tracker calibration analysis\n",
    "- Statistical summaries and visualizations\n",
    "\n",
    "This step is crucial for ensuring data quality before statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passed unknown parameter: date\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passed unknown parameter: min_n_trials_per_condition\n",
      "Passed unknown parameter: full_preprocessing\n",
      "Passed unknown parameter: run_test\n",
      "Input notebook does not contain a cell with tag 'parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run gap preprocessing notebook\n",
      "Executing notebook: 2_gap_et_preprocessing.ipynb\n",
      "Parameters: {'date': '2025_06_29', 'min_n_trials_per_condition': 6, 'full_preprocessing': False, 'run_test': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1d8cf3d5ff44a8b21802661d41c78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/50 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úó Error executing notebook: 'charmap' codec can't decode byte 0x8d in position 74417: character maps to <undefined>\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 74417: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m preprocessing_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025_06_29\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_n_trials_per_condition\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m6\u001b[39m,  \u001b[38;5;66;03m# Minimum trials required per condition\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun gap preprocessing notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m execute_notebook_with_papermill(\n\u001b[0;32m     18\u001b[0m         notebook_path\u001b[38;5;241m=\u001b[39mnotebook_to_run,\n\u001b[0;32m     19\u001b[0m                 output_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(out_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgap_et_preprocessing_papermill.html\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocessing_params\n\u001b[0;32m     21\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[9], line 38\u001b[0m, in \u001b[0;36mexecute_notebook_with_papermill\u001b[1;34m(notebook_path, output_html, **parameters)\u001b[0m\n\u001b[0;32m     35\u001b[0m html_exporter\u001b[38;5;241m.\u001b[39mexclude_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Exclude input cells for cleaner output\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(executed_notebook_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 38\u001b[0m     executed_notebook \u001b[38;5;241m=\u001b[39m \u001b[43mnbformat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     html_content, _ \u001b[38;5;241m=\u001b[39m html_exporter\u001b[38;5;241m.\u001b[39mfrom_notebook_node(executed_notebook)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Save HTML output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabot\\OneDrive - McGill University\\Desktop\\Github_repos\\q1k_neurosubs\\q1k_et_neurosubs_env\\lib\\site-packages\\nbformat\\__init__.py:169\u001b[0m, in \u001b[0;36mread\u001b[1;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read a notebook from a file as a NotebookNode of the given version.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03mThe string can contain a notebook of any version.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    The notebook that was read.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fp, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:  \u001b[38;5;66;03m# noqa: PTH123\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 74417: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# Define paths and parameters for preprocessing notebook\n",
    "notebook_to_run = \"C:/Users/gabot/OneDrive - McGill University/Desktop/github_repos/q1k_neurosubs/code/et/2_gap_et_preprocessing.ipynb\"\n",
    "out_dir = Path(\"papermill_outputs/gap_et_preprocessing\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Parameters specific to preprocessing notebook\n",
    "preprocessing_params = {\n",
    "    \"date\": \"2025_06_29\",\n",
    "    \"min_n_trials_per_condition\": 6,  # Minimum trials required per condition\n",
    "    \"full_preprocessing\": False,  # Whether to process all EDF files from scratch (Time consuming)\n",
    "    \"run_test\": False  # Set to True to check for discrepancies in the methods used to export calibration\n",
    "    \n",
    "}\n",
    "\n",
    "print(\"Run gap preprocessing notebook\")\n",
    "\n",
    "execute_notebook_with_papermill(\n",
    "        notebook_path=notebook_to_run,\n",
    "                output_html=str(out_dir / \"gap_et_preprocessing_papermill.html\"),\n",
    "    **preprocessing_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy Analysis \n",
    "\n",
    "Run the preprocessing notebook with specific parameter combinations for targeted analyses. This allows for:\n",
    "- Comparison of different outlier removal strategies\n",
    "- Analysis of different data subsets (e.g., pilot vs. main study)\n",
    "- Parameter sensitivity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passed unknown parameter: date\n",
      "Passed unknown parameter: participant_removal_type\n",
      "Passed unknown parameter: age_group\n",
      "Input notebook does not contain a cell with tag 'parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run gap accuracy analysis notebook\n",
      "Executing notebook: 3_gap_accuracy_analysis.ipynb\n",
      "Parameters: {'date': 'all_Remove', 'participant_removal_type': 'remove_all', 'age_group': 'all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27766c06a0154406999d81a6e0139be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/76 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Successfully executed and saved to: papermill_outputs\\gap_accuracy_analysis\\gap_accuracy_analysis_papermill.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'papermill_outputs\\\\gap_accuracy_analysis\\\\gap_accuracy_analysis_papermill_executed.ipynb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define paths and parameters for preprocessing notebook\n",
    "notebook_to_run = \"C:/Users/gabot/OneDrive - McGill University/Desktop/github_repos/q1k_neurosubs/code/et/3_gap_accuracy_analysis.ipynb\"\n",
    "out_dir = Path(\"papermill_outputs/gap_accuracy_analysis\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Parameters specific to preprocessing notebook\n",
    "preprocessing_params = {\n",
    "    \"date\": \"2025_06_29\",\n",
    "    \"participant_removal_type\":\"remove_min_trials\",  # Can be \"remove_min_trials\", \"remove_all\"\n",
    "    \"age_group\": \"all\" # Can be \"all\", \"child\" or \"adult\"\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Run gap accuracy analysis notebook\")\n",
    "\n",
    "execute_notebook_with_papermill(\n",
    "        notebook_path=notebook_to_run,\n",
    "                output_html=str(out_dir /   \"gap_accuracy_analysis_papermill.html\"),\n",
    "    **preprocessing_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Analysis Configurations\n",
    "\n",
    "Run the preprocessing notebook with specific parameter combinations for targeted analyses. This allows for:\n",
    "- Comparison of different outlier removal strategies\n",
    "- Analysis of different data subsets (e.g., pilot vs. main study)\n",
    "- Parameter sensitivity testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Analysis Configurations\n",
    "\n",
    "Run the preprocessing notebook with specific parameter combinations for targeted analyses. This allows for:\n",
    "- Comparison of different outlier removal strategies\n",
    "- Analysis of different data subsets (e.g., pilot vs. main study)\n",
    "- Parameter sensitivity testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Analysis Configurations\n",
    "\n",
    "Run the preprocessing notebook with specific parameter combinations for targeted analyses. This allows for:\n",
    "- Comparison of different outlier removal strategies\n",
    "- Analysis of different data subsets (e.g., pilot vs. main study)\n",
    "- Parameter sensitivity testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Analysis Configurations\n",
    "\n",
    "Run the preprocessing notebook with specific parameter combinations for targeted analyses. This allows for:\n",
    "- Comparison of different outlier removal strategies\n",
    "- Analysis of different data subsets (e.g., pilot vs. main study)\n",
    "- Parameter sensitivity testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Analysis Configurations\n",
    "\n",
    "Run the preprocessing notebook with specific parameter combinations for targeted analyses. This allows for:\n",
    "- Comparison of different outlier removal strategies\n",
    "- Analysis of different data subsets (e.g., pilot vs. main study)\n",
    "- Parameter sensitivity testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Analysis Configurations\n",
    "\n",
    "Run the preprocessing notebook with specific parameter combinations for targeted analyses. This allows for:\n",
    "- Comparison of different outlier removal strategies\n",
    "- Analysis of different data subsets (e.g., pilot vs. main study)\n",
    "- Parameter sensitivity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m derivative \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# \"standard\" or \"no_pilot\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m outlier_rem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      8\u001b[0m execute_notebook_with_papermill(\n\u001b[0;32m      9\u001b[0m         notebook_path\u001b[38;5;241m=\u001b[39mnotebook_to_run,\n\u001b[0;32m     10\u001b[0m         outlier_rem_value\u001b[38;5;241m=\u001b[39moutlier_rem, date\u001b[38;5;241m=\u001b[39mdate, files_date\u001b[38;5;241m=\u001b[39mfiles_date, derivative\u001b[38;5;241m=\u001b[39mderivative,\n\u001b[1;32m---> 11\u001b[0m         output_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[43mout_dir\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_outliers_removed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the Gap overlap notebooks wih each outliers\n",
    "\n",
    "# Date\n",
    "date = \"01_24_2025\"\n",
    "files_date = \"01_20_2025\"\n",
    "derivative = \"standard\" # \"standard\" or \"no_pilot\"\n",
    "outlier_rem = False\n",
    "execute_notebook_with_papermill(\n",
    "        notebook_path=notebook_to_run,\n",
    "        outlier_rem_value=outlier_rem, date=date, files_date=files_date, derivative=derivative,\n",
    "        output_html=str(out_dir / f\"output_outliers_removed_{date}.html\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 4. Execution Summary and Utilities\n",
    " \n",
    "def list_output_files():\n",
    "    \"\"\"List all generated output files.\"\"\"\n",
    "    print(\"GENERATED OUTPUT FILES\")\n",
    "    \n",
    "    output_base = Path(\"papermill_outputs\")\n",
    "    if output_base.exists():\n",
    "        for subfolder in output_base.iterdir():\n",
    "            if subfolder.is_dir():\n",
    "                print(f\"\\nüìÅ {subfolder.name}/\")\n",
    "                for file in subfolder.iterdir():\n",
    "                    if file.suffix in ['.html', '.ipynb']:\n",
    "                        size = file.stat().st_size / 1024  # Size in KB\n",
    "                        print(f\"   üìÑ {file.name} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(\"No output directory found.\")\n",
    "\n",
    "def clean_output_files():\n",
    "    \"\"\"Clean up generated output files.\"\"\"\n",
    "    output_base = Path(\"papermill_outputs\")\n",
    "    if output_base.exists():\n",
    "        import shutil\n",
    "        shutil.rmtree(output_base)\n",
    "        print(\"üóëÔ∏è Cleaned up all output files.\")\n",
    "    else:\n",
    "        print(\"No output files to clean.\")\n",
    "\n",
    "# Show summary of outputs\n",
    "list_output_files()\n",
    "\n",
    "print(\"NOTEBOOK EXECUTION COMPLETE\")\n",
    "print(\"Use list_output_files() to see generated files\")\n",
    "print(\"Use clean_output_files() to remove all outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execution Summary and File Management\n",
    "\n",
    "Utility functions for managing outputs and summarizing execution results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q1k_et_neurosubs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
